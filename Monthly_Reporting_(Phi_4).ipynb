{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOuAGo9UoP6+NVQKy7SMmTG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alazarchuk/AI-Toolbox/blob/main/Monthly_Reporting_(Phi_4).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U transformers\n",
        "!pip install -q -U accelerate\n",
        "!pip install -q -U bitsandbytes"
      ],
      "metadata": {
        "id": "gcvt0i_yf2BL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTbNHR4IeFpD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    pipeline\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"microsoft/phi-4\""
      ],
      "metadata": {
        "id": "5UA5ObeUA8m6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "6UGnLKzxlU55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmVQKkMI9AZQ"
      },
      "outputs": [],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\")\n",
        "summarization_model = AutoModelForCausalLM.from_pretrained(\n",
        "          model_path, quantization_config=bnb_config, device_map=\"auto\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=summarization_model,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "generation_args = {\n",
        "    \"max_new_tokens\": 1000,\n",
        "    \"return_full_text\": False,\n",
        "    \"temperature\": 0.0,\n",
        "    \"do_sample\": False,\n",
        "}"
      ],
      "metadata": {
        "id": "RCPM0SAEjEUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "YsFDkkQefDub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date_start = datetime.fromisoformat(\"2025-03-01\")\n",
        "date_end = datetime.fromisoformat(\"2025-04-01\")\n",
        "author_filter = \"alazarchuk\""
      ],
      "metadata": {
        "id": "eHMpErRTxWp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(date_start)\n",
        "print(date_end)"
      ],
      "metadata": {
        "id": "Y7ePi4dBx5kU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U PyGithub"
      ],
      "metadata": {
        "id": "wdSVMOYReT4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from github import Github\n",
        "from github import Auth\n",
        "from collections import defaultdict\n",
        "\n",
        "access_token = userdata.get('GITHUB_TOKEN')\n",
        "github_orgnizations = userdata.get('GITHUB_ORGNIZATIONS').split(\",\")\n",
        "\n",
        "auth = Auth.Token(access_token)\n",
        "\n",
        "g = Github(auth=auth)\n",
        "author_filter = g.get_user().login\n",
        "\n",
        "commits_per_repo = defaultdict(list)\n",
        "\n",
        "for org_name in github_orgnizations:\n",
        "  org = g.get_organization(org_name)\n",
        "  for repo in org.get_repos():\n",
        "    commits = repo.get_commits(since=date_start, until=date_end, author=author_filter)\n",
        "    try:\n",
        "      count = commits.totalCount\n",
        "    except:\n",
        "      count = 0\n",
        "    if count > 0:\n",
        "      for commit in commits:\n",
        "        commits_per_repo[org.name + \" -> \" + repo.name].append(commit.commit.message)\n"
      ],
      "metadata": {
        "id": "NgZSRT2reuHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for repo in commits_per_repo.keys():\n",
        "  commits = commits_per_repo[repo]\n",
        "\n",
        "  summary_messages = [\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": \"Write one sentence summary in past tense on the work done based on commit messages. \" +\n",
        "                     \"Keep it not more then 20 words. \" +\n",
        "                     \"Exclude mentions of pull requests, commits and merges. \" +\n",
        "                     \"Commits: \" + \"\\n\".join(commits)}\n",
        "  ]\n",
        "\n",
        "  output = pipe(summary_messages, **generation_args)\n",
        "  print(\"=\"*60)\n",
        "  print(repo)\n",
        "  print(\"-\"*60)\n",
        "  summary = output[0]['generated_text']\n",
        "  print(summary)\n",
        "  print(\"-\"*60)\n",
        "  translate_messages = [\n",
        "        {\"role\": \"assistant\", \"content\": \"I am usefull assistant that can translate summary of developemt work from english to ukranian\"},\n",
        "        {\"role\": \"user\", \"content\": \"Fixed issues related to seeds and restoring files\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Виправив помилки пов'язаних із сідами та відновлення файлів\"},\n",
        "        {\"role\": \"user\", \"content\": \"Added additional fields to Address\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Додав додаткові поля до Адреси\"},\n",
        "        {\"role\": \"user\", \"content\": \"Refactored exception handling, enhanced code documentation and updated dependencies\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Відрефакторив обробку помилок, покращив документацію коду і оновив залежності\"},\n",
        "        {\"role\": \"user\", \"content\": summary}\n",
        "  ]\n",
        "  output = pipe(translate_messages, **generation_args)\n",
        "  translated_summary = output[0]['generated_text']\n",
        "  print(translated_summary)\n",
        "  print(\"=\"*60)"
      ],
      "metadata": {
        "id": "vJHIY7z3lxSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AOh4sabkfg9j"
      }
    }
  ]
}